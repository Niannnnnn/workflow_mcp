{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niannnnnn/workflow_mcp/blob/main/Virtual_Screening_Workflow_with_MCP_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        " import subprocess\n",
        " import os\n",
        " import logging\n",
        " from typing import List, Dict, Optional, Any\n",
        " from pathlib import Path\n",
        " from datetime import datetime\n",
        " import asyncio  # Import asyncio for async operations\n",
        " import json # Import json for parsing tool outputs if needed\n",
        "\n",
        " # Import MCP and OpenAI related libraries\n",
        " from dotenv import load_dotenv\n",
        " from openai import AsyncOpenAI\n",
        " from agents import (\n",
        "     Agent,\n",
        "     OpenAIChatCompletionsModel,\n",
        "     Runner,\n",
        "     set_default_openai_client,\n",
        "     function_tool,\n",
        "     MessageOutputItem,\n",
        "     ToolCallOutputItem,\n",
        "     ItemHelpers,\n",
        " )\n",
        "\n",
        " # --- Configuration ---\n",
        "\n",
        " # Load environment variables (e.g., for API keys)\n",
        " load_dotenv(override=True)\n",
        " API_KEY = os.getenv(\"API_KEY\", \"YOUR_DEEPSEEK_API_KEY\") # Replace with your actual key or env var name\n",
        " BASE_URL = os.getenv(\"BASE_URL\", \"[https://api.deepseek.com](https://api.deepseek.com)\") # Or your API endpoint\n",
        " WORKING_DIR = Path(os.getenv(\"WORKFLOW_WORKING_DIR\", \"/home/zhangfn/workflow_parallel\")) # Make working dir configurable\n",
        " LOG_FILE = WORKING_DIR / \"workflow_mcp.log\"\n",
        " MAX_RETRIES = 3\n",
        "\n",
        " # --- Configure Logging ---\n",
        " logging.basicConfig(\n",
        "     filename=LOG_FILE,\n",
        "     level=logging.INFO,\n",
        "     format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
        " )\n",
        " console_handler = logging.StreamHandler() # Add handler to print logs to console\n",
        " console_handler.setLevel(logging.INFO)\n",
        " formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        " console_handler.setFormatter(formatter)\n",
        " logging.getLogger().addHandler(console_handler)\n",
        "\n",
        "\n",
        " # --- Original Workflow Logic (Slightly adapted for clarity and parameterization) ---\n",
        "\n",
        " class WorkflowStep:\n",
        "     \"\"\"Base class for a single step in the workflow.\"\"\"\n",
        "     def __init__(self, name: str, working_dir: Path):\n",
        "         self.name = name\n",
        "         self.working_dir = working_dir\n",
        "         self.checkpoint_file = self.working_dir / f\"{name}_checkpoint.txt\"\n",
        "         # Ensure working directory exists\n",
        "         self.working_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "     def _run_subprocess(self, cmd: List[str], step_description: str) -> bool:\n",
        "         \"\"\"Helper to run a subprocess and log results.\"\"\"\n",
        "         logging.info(f\"Running step: {step_description} with command: {' '.join(cmd)}\")\n",
        "         try:\n",
        "             # Using asyncio.create_subprocess_exec for better async handling if needed,\n",
        "             # but subprocess.run is simpler for synchronous external tools.\n",
        "             result = subprocess.run(cmd, check=True, cwd=self.working_dir, capture_output=True, text=True)\n",
        "             logging.info(f\"{step_description} completed successfully.\")\n",
        "             logging.debug(f\"Stdout: {result.stdout}\")\n",
        "             logging.debug(f\"Stderr: {result.stderr}\")\n",
        "             return True\n",
        "         except subprocess.CalledProcessError as e:\n",
        "             logging.error(f\"{step_description} failed: {e}\")\n",
        "             logging.error(f\"Stderr: {e.stderr}\")\n",
        "             logging.error(f\"Stdout: {e.stdout}\")\n",
        "             return False\n",
        "         except FileNotFoundError as e:\n",
        "             logging.error(f\"{step_description} failed: Command not found - {e}. Ensure necessary tools are installed and in PATH.\")\n",
        "             return False\n",
        "         except Exception as e:\n",
        "             logging.error(f\"{step_description} failed with unexpected error: {e}\")\n",
        "             return False\n",
        "\n",
        "     def run(self, *args, **kwargs) -> bool:\n",
        "         raise NotImplementedError\n",
        "\n",
        "     def save_checkpoint(self):\n",
        "         \"\"\"Save checkpoint, including current time.\"\"\"\n",
        "         current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "         try:\n",
        "             with open(self.checkpoint_file, \"w\") as f:\n",
        "                 f.write(f\"completed at {current_time}\")\n",
        "             logging.info(f\"Checkpoint saved for {self.name} at {current_time}\")\n",
        "         except IOError as e:\n",
        "             logging.error(f\"Failed to save checkpoint for {self.name}: {e}\")\n",
        "\n",
        "     def check_checkpoint(self) -> bool:\n",
        "         \"\"\"Check if the step is already completed.\"\"\"\n",
        "         exists = self.checkpoint_file.exists()\n",
        "         if exists:\n",
        "             logging.info(f\"Checkpoint found for {self.name}, skipping step.\")\n",
        "         return exists\n",
        "\n",
        "     def clear_checkpoint(self):\n",
        "         \"\"\"Clears the checkpoint file for this step.\"\"\"\n",
        "         try:\n",
        "             if self.checkpoint_file.exists():\n",
        "                 self.checkpoint_file.unlink()\n",
        "                 logging.info(f\"Cleared checkpoint for {self.name}.\")\n",
        "         except OSError as e:\n",
        "             logging.warning(f\"Failed to clear checkpoint file {self.checkpoint_file}: {e}\")\n",
        "\n",
        "\n",
        " class MoleculeGeneration(WorkflowStep):\n",
        "     \"\"\"Molecule Generation Step\"\"\"\n",
        "     def __init__(self, working_dir: Path):\n",
        "         super().__init__(\"mol_generate\", working_dir)\n",
        "\n",
        "     def run(self, pdb_file: str, outfile: str, ref_ligand: str, n_samples: int = 1) -> bool:\n",
        "         if self.check_checkpoint():\n",
        "             return True\n",
        "\n",
        "         # --- Parameter Validation ---\n",
        "         pdb_path = Path(pdb_file)\n",
        "         if not pdb_path.is_file() or pdb_path.suffix != \".pdb\":\n",
        "              logging.error(f\"Invalid PDB file path or format: {pdb_file}\")\n",
        "              # Consider raising an error or returning specific failure info\n",
        "              return False # Indicate failure due to bad input\n",
        "\n",
        "         # Convert paths to absolute strings for subprocess\n",
        "         pdb_file_abs = str(pdb_path.resolve())\n",
        "         outfile_abs = str((self.working_dir / outfile).resolve())\n",
        "         # Ensure output directory exists if outfile includes directories\n",
        "         Path(outfile_abs).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "         # --- Command Construction ---\n",
        "         # IMPORTANT: Replace hardcoded paths with configurable ones or ensure they are correct\n",
        "         generate_script = \"/home/zhangfn/DiffSBDD/generate_ligands.py\" # Example: Make this configurable\n",
        "         checkpoint_ckpt = \"/home/zhangfn/DiffSBDD/checkpoints/crossdocked_fullatom_cond.ckpt\" # Example: Make this configurable\n",
        "\n",
        "         if not Path(generate_script).exists() or not Path(checkpoint_ckpt).exists():\n",
        "             logging.error(\"Molecule generation script or checkpoint not found. Please check paths.\")\n",
        "             return False\n",
        "\n",
        "         cmd = [\n",
        "             \"python3\", generate_script,\n",
        "             checkpoint_ckpt,\n",
        "             \"--pdbfile\", pdb_file_abs,\n",
        "             \"--outfile\", outfile_abs,\n",
        "             \"--ref_ligand\", ref_ligand,\n",
        "             \"--n_samples\", str(n_samples)\n",
        "         ]\n",
        "\n",
        "         # --- Execution ---\n",
        "         success = self._run_subprocess(cmd, \"Molecule Generation\")\n",
        "         if success:\n",
        "             self.save_checkpoint()\n",
        "             logging.info(f\"Molecule generation completed successfully. Output: {outfile_abs}\")\n",
        "         else:\n",
        "             logging.error(\"Molecule generation failed.\")\n",
        "         return success\n",
        "\n",
        "\n",
        " class MolecularDocking(WorkflowStep):\n",
        "     \"\"\"Molecular Docking Step\"\"\"\n",
        "     def __init__(self, working_dir: Path):\n",
        "         super().__init__(\"dock\", working_dir)\n",
        "         self.grid_center: Optional[List[float]] = None\n",
        "\n",
        "     def run(self, ligand_sdf: str, protein_pdb: str, dock_mode: str = \"adgpu\") -> bool:\n",
        "         if self.check_checkpoint():\n",
        "             return True\n",
        "\n",
        "         # --- Parameter Validation ---\n",
        "         ligand_sdf_path = self.working_dir / ligand_sdf\n",
        "         protein_pdb_path = Path(protein_pdb) # Assume protein path can be absolute or relative\n",
        "         if not ligand_sdf_path.is_file() or ligand_sdf_path.suffix != \".sdf\":\n",
        "             logging.error(f\"Ligand SDF file not found or invalid format: {ligand_sdf_path}\")\n",
        "             return False\n",
        "         if not protein_pdb_path.is_file() or protein_pdb_path.suffix != \".pdb\":\n",
        "             logging.error(f\"Protein PDB file not found or invalid format: {protein_pdb_path}\")\n",
        "             return False\n",
        "         if dock_mode not in [\"adgpu\", \"vina\"]:\n",
        "             logging.error(f\"Invalid docking mode: {dock_mode}. Choose 'adgpu' or 'vina'.\")\n",
        "             return False\n",
        "\n",
        "         # --- File Naming and Paths ---\n",
        "         ligand_base_name = ligand_sdf_path.stem\n",
        "         protein_base_name = protein_pdb_path.stem\n",
        "         self.ligand_pdbqt = self.working_dir / f\"{ligand_base_name}.pdbqt\"\n",
        "         self.protein_pdbqt = self.working_dir / f\"{protein_base_name}.pdbqt\"\n",
        "         self.gpf_file = self.working_dir / f\"{protein_base_name}_{ligand_base_name}.gpf\"\n",
        "         self.fld_file = self.working_dir / f\"{protein_base_name}.maps.fld\" # ADGPU specific\n",
        "         self.dlg_file = self.working_dir / f\"{ligand_base_name}.dlg\" # ADGPU specific output log/results\n",
        "\n",
        "         # Create output directories\n",
        "         self.output_dir = self.working_dir / \"dock\" / dock_mode\n",
        "         self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "         self.vina_outfile = self.output_dir / f\"{ligand_base_name}_vina_out.pdbqt\" # Vina specific output\n",
        "         self.adgpu_log = self.output_dir / f\"{ligand_base_name}_adgpu.log\" # ADGPU specific log\n",
        "\n",
        "         # --- Workflow Steps ---\n",
        "         steps = [\n",
        "             (self._convert_ligand_format, \"Convert ligand SDF to PDBQT\", [str(ligand_sdf_path), str(self.ligand_pdbqt)]),\n",
        "             (self._convert_receptor_format, \"Convert receptor PDB to PDBQT\", [str(protein_pdb_path), str(self.protein_pdbqt)]),\n",
        "             (self._calculate_grid_center, \"Calculate grid center\", [str(protein_pdb_path)]), # Pass protein PDB to find pocket\n",
        "             (self._generate_gpf_file, \"Generate GPF file\", []),\n",
        "             # FLD generation is specific to ADGPU workflow usually triggered by autogrid\n",
        "             # Vina calculates grids internally based on center/size\n",
        "         ]\n",
        "\n",
        "         if dock_mode == \"adgpu\":\n",
        "             steps.extend([\n",
        "                 (self._generate_fld_file, \"Generate FLD file (autogrid)\", []),\n",
        "                 (self._run_docking_adgpu, \"Run AutoDock GPU docking\", []),\n",
        "                 (self._convert_dlg_to_pdbqt, \"Convert DLG to PDBQT\", []) # Convert ADGPU results\n",
        "             ])\n",
        "         elif dock_mode == \"vina\":\n",
        "             steps.append(\n",
        "                 (self._run_docking_vina, \"Run AutoDock Vina docking\", [])\n",
        "             )\n",
        "\n",
        "         # --- Execute Steps ---\n",
        "         for func, desc, args in steps:\n",
        "             try:\n",
        "                 if not func(*args): # Pass arguments to the step function\n",
        "                     logging.error(f\"Docking failed during step: {desc}\")\n",
        "                     return False\n",
        "                 logging.info(f\"{desc} completed successfully.\")\n",
        "             except Exception as e:\n",
        "                 logging.error(f\"Error during docking step '{desc}': {e}\", exc_info=True)\n",
        "                 return False\n",
        "\n",
        "         self.save_checkpoint()\n",
        "         logging.info(f\"Molecular docking ({dock_mode}) completed successfully. Outputs in {self.output_dir}\")\n",
        "         return True\n",
        "\n",
        "     # --- Helper methods for docking steps ---\n",
        "     # (These methods now return bool for success/failure)\n",
        "\n",
        "     def _convert_ligand_format(self, input_sdf: str, output_pdbqt: str) -> bool:\n",
        "         \"\"\"Convert ligand SDF to PDBQT using Open Babel.\"\"\"\n",
        "         logging.info(f\"Converting {input_sdf} to {output_pdbqt}\")\n",
        "         try:\n",
        "             # Using pybel API directly is often more robust than subprocess for simple conversions\n",
        "             mols = list(pybel.readfile(\"sdf\", input_sdf))\n",
        "             if not mols:\n",
        "                 logging.error(f\"No molecules found in {input_sdf}\")\n",
        "                 return False\n",
        "             # Write the first molecule (assuming single ligand file)\n",
        "             mols[0].write(\"pdbqt\", output_pdbqt, overwrite=True)\n",
        "             logging.info(\"Ligand format conversion successful.\")\n",
        "             return True\n",
        "         except Exception as e:\n",
        "             logging.error(f\"Open Babel conversion failed: {e}\", exc_info=True)\n",
        "             return False\n",
        "\n",
        "     def _convert_receptor_format(self, input_pdb: str, output_pdbqt: str) -> bool:\n",
        "         \"\"\"Convert receptor PDB to PDBQT using MGLTools.\"\"\"\n",
        "         # IMPORTANT: Replace hardcoded paths\n",
        "         mgltools_python = \"/home/zhangfn/.conda/envs/targetdiff/bin/python\" # Configurable\n",
        "         prepare_receptor_script = \"/home/zhangfn/mgltools_x86_64Linux2_1.5.7/MGLToolsPckgs/AutoDockTools/Utilities24/prepare_receptor4.py\" # Configurable\n",
        "\n",
        "         if not Path(mgltools_python).exists() or not Path(prepare_receptor_script).exists():\n",
        "             logging.error(\"MGLTools python or prepare_receptor script not found.\")\n",
        "             return False\n",
        "\n",
        "         cmd = [\n",
        "             mgltools_python,\n",
        "             prepare_receptor_script,\n",
        "             \"-r\", input_pdb,\n",
        "             \"-A\", \"hydrogens\", # Add hydrogens (common practice)\n",
        "             \"-U\", \"nphs_lps\",  # Merge non-polar hydrogens and lone pairs\n",
        "             \"-v\",\n",
        "             \"-o\", output_pdbqt\n",
        "         ]\n",
        "         return self._run_subprocess(cmd, \"Receptor PDB to PDBQT conversion\")\n",
        "\n",
        "     def _calculate_grid_center(self, protein_pdb_path: str) -> bool:\n",
        "         \"\"\"Calculate grid center using external script.\"\"\"\n",
        "         # IMPORTANT: Replace hardcoded path\n",
        "         grid_center_script = \"/home/zhangfn/workflow_parallel/grid_center.py\" # Configurable? Or needs ligand context?\n",
        "         # This script likely needs the PDB file as input or context. Assuming it works based on PDB in cwd.\n",
        "         # A better approach might be to pass the PDB path to the script.\n",
        "\n",
        "         if not Path(grid_center_script).exists():\n",
        "             logging.error(f\"Grid center script not found: {grid_center_script}\")\n",
        "             return False\n",
        "\n",
        "         # We need to ensure the script uses the correct protein PDB.\n",
        "         # Option 1: Modify grid_center.py to accept the PDB path as an argument.\n",
        "         # Option 2: Copy the PDB to the working directory if it's not already there. (Less ideal)\n",
        "         # Assuming Option 1 is implemented in grid_center.py:\n",
        "         # cmd = [\"python3\", grid_center_script, protein_pdb_path]\n",
        "         # If grid_center.py reads a fixed file name, ensure it's the correct one.\n",
        "         # For now, assume it works on a PDB in the working dir. Needs clarification.\n",
        "         cmd = [\"python3\", grid_center_script] # Simplistic assumption\n",
        "\n",
        "         if not self._run_subprocess(cmd, \"Grid Center Calculation\"):\n",
        "             return False\n",
        "\n",
        "         # Read the calculated center\n",
        "         pocket_file = self.working_dir / \"pocket_center.txt\"\n",
        "         try:\n",
        "             if pocket_file.exists():\n",
        "                 with open(pocket_file, 'r') as f:\n",
        "                     center_coords = f.read().strip().split(',')\n",
        "                 if len(center_coords) == 3:\n",
        "                     self.grid_center = [float(coord) for coord in center_coords]\n",
        "                     logging.info(f\"Grid center calculated: {self.grid_center}\")\n",
        "                     return True\n",
        "                 else:\n",
        "                     logging.error(\"pocket_center.txt has invalid format.\")\n",
        "                     return False\n",
        "             else:\n",
        "                 logging.error(\"pocket_center.txt was not generated.\")\n",
        "                 return False\n",
        "         except Exception as e:\n",
        "             logging.error(f\"Error reading pocket_center.txt: {e}\")\n",
        "             return False\n",
        "\n",
        "\n",
        "     def _generate_gpf_file(self) -> bool:\n",
        "         \"\"\"Generate GPF file using MGLTools.\"\"\"\n",
        "         if self.grid_center is None:\n",
        "             logging.error(\"Grid center not calculated, cannot generate GPF.\")\n",
        "             return False\n",
        "\n",
        "         # IMPORTANT: Replace hardcoded paths\n",
        "         mgltools_python = \"/home/zhangfn/.conda/envs/targetdiff/bin/python\" # Configurable\n",
        "         prepare_gpf_script = \"/home/zhangfn/mgltools_x86_64Linux2_1.5.7/MGLToolsPckgs/AutoDockTools/Utilities24/prepare_gpf4.py\" # Configurable\n",
        "\n",
        "         if not Path(mgltools_python).exists() or not Path(prepare_gpf_script).exists():\n",
        "             logging.error(\"MGLTools python or prepare_gpf script not found.\")\n",
        "             return False\n",
        "\n",
        "         gridcenter_str = \",\".join(map(str, self.grid_center))\n",
        "         cmd = [\n",
        "             mgltools_python,\n",
        "             prepare_gpf_script,\n",
        "             \"-l\", str(self.ligand_pdbqt),\n",
        "             \"-r\", str(self.protein_pdbqt),\n",
        "             \"-o\", str(self.gpf_file),\n",
        "             \"-p\", \"npts=30,30,30\", # Grid dimensions - make configurable?\n",
        "             \"-p\", \"spacing=0.375\", # Grid spacing - make configurable?\n",
        "             \"-p\", \"ligand_types=C,SA,N,HD,OA,Br,NA,I,A,Cl,F,P,S\", # Atom types - ensure comprehensive\n",
        "             \"-p\", f\"gridcenter={gridcenter_str}\"\n",
        "         ]\n",
        "         return self._run_subprocess(cmd, \"GPF file generation\")\n",
        "\n",
        "     def _generate_fld_file(self) -> bool:\n",
        "         \"\"\"Generate FLD file using AutoGrid.\"\"\"\n",
        "         if not self.gpf_file.exists():\n",
        "             logging.error(f\"GPF file not found ({self.gpf_file}), cannot run autogrid.\")\n",
        "             return False\n",
        "\n",
        "         # IMPORTANT: Replace hardcoded path\n",
        "         autogrid_executable = \"/home/zhangfn/x86_64Linux2/autogrid4\" # Configurable\n",
        "\n",
        "         if not Path(autogrid_executable).exists():\n",
        "             logging.error(f\"AutoGrid executable not found: {autogrid_executable}\")\n",
        "             return False\n",
        "\n",
        "         cmd = [autogrid_executable, \"-p\", str(self.gpf_file.name)] # Run autogrid with gpf filename\n",
        "         # Autogrid usually outputs a log file, useful for debugging\n",
        "         log_file = self.working_dir / f\"{self.gpf_file.stem}.glg\"\n",
        "         logging.info(f\"Running AutoGrid. Log file: {log_file}\")\n",
        "\n",
        "         return self._run_subprocess(cmd, \"FLD file generation (autogrid)\")\n",
        "\n",
        "     def _run_docking_adgpu(self) -> bool:\n",
        "         \"\"\"Run AutoDock GPU docking.\"\"\"\n",
        "         if not self.fld_file.exists():\n",
        "             logging.error(f\"FLD file not found ({self.fld_file}), cannot run AutoDock GPU.\")\n",
        "             return False\n",
        "         if not self.ligand_pdbqt.exists():\n",
        "             logging.error(f\"Ligand PDBQT file not found ({self.ligand_pdbqt}), cannot run AutoDock GPU.\")\n",
        "             return False\n",
        "\n",
        "         # IMPORTANT: Replace hardcoded path\n",
        "         adgpu_executable = \"/home/zhangfn/AutoDock-GPU-develop/bin/autodock_gpu_64wi\" # Configurable\n",
        "\n",
        "         if not Path(adgpu_executable).exists():\n",
        "             logging.error(f\"AutoDock GPU executable not found: {adgpu_executable}\")\n",
        "             return False\n",
        "\n",
        "         cmd = [\n",
        "             adgpu_executable,\n",
        "             \"--ffile\", str(self.fld_file.name), # Use filename relative to working dir\n",
        "             \"--lfile\", str(self.ligand_pdbqt.name), # Use filename relative to working dir\n",
        "             \"-nrun\", \"10\", # Number of runs - make configurable?\n",
        "             # Add other ADGPU options as needed, e.g., -lsmet, -nev, etc.\n",
        "             # Output is typically a DLG file named after the ligand + .dlg\n",
        "             # Explicitly specify output log/dlg file is better if possible\n",
        "             # Example: \"-olog\", str(self.dlg_file.name) # Check if ADGPU supports -olog\n",
        "         ]\n",
        "         # Redirect output to a log file\n",
        "         logging.info(f\"Running AutoDock GPU. Output/Log will be {self.dlg_file.name} (and potentially {self.adgpu_log.name})\")\n",
        "         # ADGPU might write directly to DLG, let's capture subprocess output to adgpu_log\n",
        "         try:\n",
        "             with open(self.adgpu_log, 'w') as f:\n",
        "                 result = subprocess.run(cmd, check=True, cwd=self.working_dir, stdout=f, stderr=subprocess.STDOUT, text=True)\n",
        "             logging.info(f\"AutoDock GPU completed. Log: {self.adgpu_log}\")\n",
        "             # Check if DLG file was created\n",
        "             if not self.dlg_file.exists():\n",
        "                 logging.warning(f\"Expected DLG file {self.dlg_file} was not created by AutoDock GPU.\")\n",
        "                 # Consider this a failure depending on requirements\n",
        "                 # return False\n",
        "             return True\n",
        "         except subprocess.CalledProcessError as e:\n",
        "             logging.error(f\"AutoDock GPU failed: {e}\")\n",
        "             logging.error(f\"Check log file for details: {self.adgpu_log}\")\n",
        "             return False\n",
        "         except Exception as e:\n",
        "             logging.error(f\"Error running AutoDock GPU: {e}\")\n",
        "             return False\n",
        "\n",
        "     def _run_docking_vina(self) -> bool:\n",
        "         \"\"\"Run AutoDock Vina docking.\"\"\"\n",
        "         if self.grid_center is None:\n",
        "             logging.error(\"Grid center not calculated, cannot run Vina.\")\n",
        "             return False\n",
        "         if not self.protein_pdbqt.exists() or not self.ligand_pdbqt.exists():\n",
        "             logging.error(\"Receptor or Ligand PDBQT file not found for Vina.\")\n",
        "             return False\n",
        "\n",
        "         # Vina executable should be in PATH or specified\n",
        "         vina_executable = \"vina\" # Assumes vina is in PATH\n",
        "\n",
        "         cmd = [\n",
        "             vina_executable,\n",
        "             \"--receptor\", str(self.protein_pdbqt.name),\n",
        "             \"--ligand\", str(self.ligand_pdbqt.name),\n",
        "             \"--out\", str(self.vina_outfile.relative_to(self.working_dir)), # Path relative to CWD\n",
        "             \"--center_x\", str(self.grid_center[0]),\n",
        "             \"--center_y\", str(self.grid_center[1]),\n",
        "             \"--center_z\", str(self.grid_center[2]),\n",
        "             \"--size_x\", \"30\", # Box size - make configurable?\n",
        "             \"--size_y\", \"30\",\n",
        "             \"--size_z\", \"30\",\n",
        "             # Add other Vina options like --exhaustiveness, --num_modes\n",
        "             \"--cpu\", \"4\", # Example: Use 4 CPUs\n",
        "             \"--log\", str(self.output_dir / f\"{self.ligand_pdbqt.stem}_vina.log\") # Specify log file\n",
        "         ]\n",
        "         return self._run_subprocess(cmd, \"AutoDock Vina docking\")\n",
        "\n",
        "     def _convert_dlg_to_pdbqt(self) -> bool:\n",
        "         \"\"\"Convert ADGPU DLG file to PDBQT files.\"\"\"\n",
        "         if not self.dlg_file.exists():\n",
        "             logging.warning(f\"DLG file {self.dlg_file} not found, cannot convert to PDBQT. Skipping.\")\n",
        "             # Depending on workflow, this might be an error or just no results to convert\n",
        "             return True # Or False if DLG is mandatory\n",
        "\n",
        "         # IMPORTANT: Replace hardcoded path\n",
        "         dlg2pdbqt_script = \"/home/zhangfn/workflow_parallel/dlg2pdbqt.py\" # Configurable\n",
        "\n",
        "         if not Path(dlg2pdbqt_script).exists():\n",
        "             logging.error(f\"dlg2pdbqt script not found: {dlg2pdbqt_script}\")\n",
        "             return False\n",
        "\n",
        "         cmd = [\n",
        "             \"python3\",\n",
        "             dlg2pdbqt_script,\n",
        "             str(self.dlg_file.name) # Pass DLG filename relative to CWD\n",
        "             # Ensure the script writes output to the correct directory (self.output_dir)\n",
        "         ]\n",
        "         # This script might create multiple PDBQT files in the CWD or a subdir.\n",
        "         # Need to know its behavior to confirm success.\n",
        "         success = self._run_subprocess(cmd, \"DLG to PDBQT conversion\")\n",
        "         if success:\n",
        "              logging.info(f\"DLG converted. PDBQT files should be in {self.working_dir} or {self.output_dir}\")\n",
        "              # Add check here if possible: e.g., check if any *.pdbqt files were created in output_dir\n",
        "         return success\n",
        "\n",
        "\n",
        " class ConformationEvaluation(WorkflowStep):\n",
        "     \"\"\"Conformation Evaluation Step\"\"\"\n",
        "     def __init__(self, working_dir: Path):\n",
        "         super().__init__(\"eval\", working_dir)\n",
        "\n",
        "     def run(self, mode: str, dock_output_dir: Optional[str] = None, mol_file: Optional[str] = None) -> bool:\n",
        "         \"\"\"\n",
        "         Run conformation evaluation.\n",
        "\n",
        "         Args:\n",
        "             mode (str): Evaluation mode, either 'redock' or 'mol'.\n",
        "             dock_output_dir (Optional[str]): Path to the docking output directory (required for 'redock' mode).\n",
        "                                               Should contain PDBQT files from docking.\n",
        "             mol_file (Optional[str]): Path to the input molecule file (required for 'mol' mode).\n",
        "                                         Can be SDF, PDBQT etc. depending on pb.py script.\n",
        "         \"\"\"\n",
        "         if self.check_checkpoint():\n",
        "             return True\n",
        "\n",
        "         # --- Parameter Validation ---\n",
        "         if mode not in [\"redock\", \"mol\"]:\n",
        "             logging.error(f\"Invalid evaluation mode: {mode}. Choose 'redock' or 'mol'.\")\n",
        "             return False\n",
        "         if mode == \"redock\" and not dock_output_dir:\n",
        "             logging.error(\"Docking output directory is required for 'redock' mode.\")\n",
        "             return False\n",
        "         if mode == \"mol\" and not mol_file:\n",
        "             logging.error(\"Input molecule file is required for 'mol' mode.\")\n",
        "             return False\n",
        "\n",
        "         # --- Path Setup ---\n",
        "         # IMPORTANT: Replace hardcoded paths\n",
        "         pdbqt2sdf_adgpu_script = \"/home/zhangfn/workflow_parallel/pdbqt2sdf_adgpu.py\" # Configurable\n",
        "         pdbqt2sdf_vina_script = \"/home/zhangfn/workflow_parallel/pdbqt2sdf_vina.py\" # Configurable\n",
        "         pb_script = \"/home/zhangfn/workflow_parallel/pb.py\" # Configurable\n",
        "\n",
        "         # Ensure scripts exist\n",
        "         scripts_to_check = [pb_script]\n",
        "         if mode == \"redock\":\n",
        "              # Need to know which converter to use based on docking mode, which isn't passed here directly.\n",
        "              # This highlights a dependency issue. The evaluation step needs to know the source of the PDBQTs.\n",
        "              # For now, assume we need both potentially, or add logic to determine which one.\n",
        "              scripts_to_check.extend([pdbqt2sdf_adgpu_script, pdbqt2sdf_vina_script])\n",
        "\n",
        "         for script in scripts_to_check:\n",
        "              if not Path(script).exists():\n",
        "                  logging.error(f\"Required evaluation script not found: {script}\")\n",
        "                  return False\n",
        "\n",
        "         # --- Workflow Steps ---\n",
        "         steps = []\n",
        "         eval_output_dir = self.working_dir / \"eval\" / mode\n",
        "         eval_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "         if mode == \"redock\":\n",
        "             dock_output_path = Path(dock_output_dir)\n",
        "             if not dock_output_path.is_dir():\n",
        "                 logging.error(f\"Docking output directory not found: {dock_output_path}\")\n",
        "                 return False\n",
        "\n",
        "             # Determine which PDBQT->SDF script to use. This requires knowing the docking mode used previously.\n",
        "             # This info isn't directly available here. We need to infer it or pass it.\n",
        "             # Option 1: Check for typical output files (e.g., *.dlg indicates adgpu).\n",
        "             # Option 2: Pass the original dock_mode to this function. (Better)\n",
        "             # Let's assume dock_mode is passed or inferred. For now, we guess based on dir name.\n",
        "             dock_mode_inferred = dock_output_path.name # 'adgpu' or 'vina' if named conventionally\n",
        "             pdbqt2sdf_script = \"\"\n",
        "             if dock_mode_inferred == \"adgpu\":\n",
        "                 pdbqt2sdf_script = pdbqt2sdf_adgpu_script\n",
        "             elif dock_mode_inferred == \"vina\":\n",
        "                 pdbqt2sdf_script = pdbqt2sdf_vina_script\n",
        "             else:\n",
        "                 logging.error(\"Could not determine docking mode for redock evaluation. Cannot choose PDBQT->SDF script.\")\n",
        "                 return False\n",
        "\n",
        "             # Step 1: Convert PDBQT results in dock_output_dir to SDF (needed by pb.py?)\n",
        "             # The conversion scripts need modification to process a directory of PDBQTs\n",
        "             # and output SDFs (e.g., into eval_output_dir).\n",
        "             # Assuming the scripts handle this:\n",
        "             cmd_convert = [\"python3\", pdbqt2sdf_script, str(dock_output_path), str(eval_output_dir)] # Example command structure\n",
        "             steps.append((cmd_convert, f\"Convert {dock_mode_inferred} PDBQTs to SDF\"))\n",
        "\n",
        "             # Step 2: Run PB evaluation on the generated SDFs (or directly on PDBQTs if pb.py supports it)\n",
        "             # Assuming pb.py takes the directory of results as input\n",
        "             cmd_pb = [\"python3\", pb_script, \"--config\", \"redock\", \"--input_dir\", str(eval_output_dir)] # Or dock_output_path if pb.py uses PDBQTs\n",
        "             steps.append((cmd_pb, f\"Run PB evaluation (redock mode on {dock_mode_inferred} results)\"))\n",
        "\n",
        "         elif mode == \"mol\":\n",
        "             mol_file_path = Path(mol_file)\n",
        "             if not mol_file_path.is_file():\n",
        "                 logging.error(f\"Input molecule file not found: {mol_file_path}\")\n",
        "                 return False\n",
        "             # Ensure the input molecule file is copied or accessible in the working directory if needed by pb.py\n",
        "             target_mol_file = self.working_dir / mol_file_path.name # Copy to working dir for simplicity\n",
        "             if not target_mol_file.exists():\n",
        "                  import shutil\n",
        "                  try:\n",
        "                      shutil.copy(str(mol_file_path.resolve()), target_mol_file)\n",
        "                  except Exception as e:\n",
        "                      logging.error(f\"Failed to copy input molecule file {mol_file_path} to working directory: {e}\")\n",
        "                      return False\n",
        "\n",
        "             cmd_pb = [\"python3\", pb_script, \"--config\", \"mol\", \"--input\", str(target_mol_file.name)] # Use relative path\n",
        "             steps.append((cmd_pb, \"Run PB evaluation (mol mode)\"))\n",
        "\n",
        "         # --- Execute Steps ---\n",
        "         for cmd, desc in steps:\n",
        "             if not self._run_subprocess(cmd, desc):\n",
        "                 logging.error(f\"Evaluation failed during step: {desc}\")\n",
        "                 return False\n",
        "\n",
        "         self.save_checkpoint()\n",
        "         logging.info(f\"Conformation evaluation ({mode}) completed successfully. Outputs in {eval_output_dir}\")\n",
        "         return True\n",
        "\n",
        "\n",
        " # --- MCP Agent Setup ---\n",
        "\n",
        " # Configure the OpenAI client (using DeepSeek in this case)\n",
        " try:\n",
        "     external_client = AsyncOpenAI(\n",
        "         base_url=BASE_URL,\n",
        "         api_key=API_KEY,\n",
        "         timeout=60.0, # Increase timeout if needed\n",
        "     )\n",
        "     set_default_openai_client(external_client)\n",
        "     logging.info(f\"AsyncOpenAI client configured for base URL: {BASE_URL}\")\n",
        " except Exception as e:\n",
        "     logging.error(f\"Failed to initialize AsyncOpenAI client: {e}\")\n",
        "     # Exit or handle appropriately if client setup fails\n",
        "     exit(1)\n",
        "\n",
        "\n",
        " # Define the LLM model to use with the agent\n",
        " deepseek_model = OpenAIChatCompletionsModel(\n",
        "     model=\"deepseek-chat\", # Or another model like deepseek-coder if better for tool use\n",
        "     # model=\"deepseek-coder\",\n",
        "     openai_client=external_client,\n",
        "     max_tokens=4096, # Adjust as needed\n",
        "     temperature=0.1, # Lower temperature for more deterministic tool calls\n",
        " )\n",
        "\n",
        " # Define the Agent\n",
        " # Instructions guide the agent on how to behave and use tools.\n",
        " agent_instructions = f\"\"\"\n",
        " You are a helpful assistant managing a computational chemistry workflow for virtual screening.\n",
        " Your goal is to understand the user's request and execute the necessary steps using the available tools.\n",
        " The workflow involves three main stages: Molecule Generation, Molecular Docking, and Conformation Evaluation.\n",
        " The working directory for all operations is: {WORKING_DIR}\n",
        "\n",
        " Available Tools:\n",
        " 1.  `run_molecule_generation`: Generates new ligand molecules based on a protein structure.\n",
        " 2.  `run_molecular_docking`: Docks generated or provided ligands to a protein structure using AutoDock GPU or Vina.\n",
        " 3.  `run_conformation_evaluation`: Evaluates the quality of generated molecules or docking poses.\n",
        "\n",
        " Workflow Logic:\n",
        " - Docking typically requires molecules generated by `run_molecule_generation` (an SDF file).\n",
        " - Evaluation in 'redock' mode requires the output directory from a previous docking run.\n",
        " - Evaluation in 'mol' mode requires a specific molecule file (e.g., SDF, PDBQT).\n",
        " - You MUST determine the correct file paths and parameters for each step based on the user request and workflow context.\n",
        " - Ask for clarification if the user's request is ambiguous or missing necessary information (like file paths, PDB IDs, reference ligands, docking modes).\n",
        " - Assume standard parameters if not specified, but confirm potentially critical ones like docking mode.\n",
        " - Report the success or failure of each step back to the user.\n",
        " - Ensure all file paths provided to tools are relative to the working directory '{WORKING_DIR}' or absolute paths. Intermediate files are typically stored within this directory.\n",
        "\n",
        " Example Interaction:\n",
        " User: Generate 5 molecules for PDB ID 3Rfm, using residue A:330 as reference. Then dock them using ADGPU.\n",
        " Assistant: Okay, I will first generate 5 molecules for PDB 3Rfm (assuming the file is at {WORKING_DIR}/3rfm.pdb) using reference A:330, saving to 'generated_mols.sdf'. Then I will dock 'generated_mols.sdf' to '3rfm.pdb' using ADGPU.\n",
        "\n",
        " IMPORTANT: Before executing, confirm the exact paths for input files (like the protein PDB) if not provided explicitly or if the standard name (e.g., {WORKING_DIR}/<pdb_id>.pdb) is not confirmed.\n",
        " \"\"\"\n",
        "\n",
        " workflow_agent = Agent(\n",
        "     name=\"VirtualScreeningAssistant\",\n",
        "     instructions=agent_instructions,\n",
        "     model=deepseek_model,\n",
        "     # Tools will be automatically collected via the @function_tool decorator\n",
        " )\n",
        "\n",
        " # --- Define Tools for the Agent ---\n",
        "\n",
        " # Instantiate step runners (manage state like checkpoints)\n",
        " # Pass the configured WORKING_DIR\n",
        " mol_generator = MoleculeGeneration(WORKING_DIR)\n",
        " docker = MolecularDocking(WORKING_DIR)\n",
        " evaluator = ConformationEvaluation(WORKING_DIR)\n",
        "\n",
        " @function_tool(agent=workflow_agent)\n",
        " async def run_molecule_generation(pdb_file: str, outfile_name: str, ref_ligand: str, n_samples: int = 1):\n",
        "     \"\"\"\n",
        "     Generates new ligand molecules based on a protein structure (PDB file).\n",
        "\n",
        "     Args:\n",
        "         pdb_file (str): Path to the input protein PDB file (e.g., '/path/to/protein.pdb' or relative 'protein.pdb').\n",
        "         outfile_name (str): Name for the output SDF file (e.g., 'generated_mols.sdf'). Will be saved in the working directory.\n",
        "         ref_ligand (str): Reference ligand identifier (e.g., 'A:330' or chain:resid).\n",
        "         n_samples (int): Number of molecules to generate. Defaults to 1.\n",
        "     \"\"\"\n",
        "     logging.info(f\"Tool 'run_molecule_generation' called with: pdb_file={pdb_file}, outfile_name={outfile_name}, ref_ligand={ref_ligand}, n_samples={n_samples}\")\n",
        "\n",
        "     # Resolve PDB file path relative to working dir if not absolute\n",
        "     pdb_path = Path(pdb_file)\n",
        "     if not pdb_path.is_absolute():\n",
        "         pdb_path = (WORKING_DIR / pdb_file).resolve()\n",
        "     else:\n",
        "         pdb_path = pdb_path.resolve() # Ensure it's resolved\n",
        "\n",
        "     if not pdb_path.exists():\n",
        "         return f\"Error: PDB file not found at {pdb_path}\"\n",
        "\n",
        "     # Clear previous checkpoint for this step if running explicitly\n",
        "     mol_generator.clear_checkpoint()\n",
        "\n",
        "     # Run the step\n",
        "     success = await asyncio.to_thread(\n",
        "         mol_generator.run,\n",
        "         pdb_file=str(pdb_path),\n",
        "         outfile=outfile_name, # Pass only the name, path is handled internally\n",
        "         ref_ligand=ref_ligand,\n",
        "         n_samples=n_samples\n",
        "     )\n",
        "\n",
        "     if success:\n",
        "         output_path = WORKING_DIR / outfile_name\n",
        "         return f\"Molecule generation completed successfully. Output file: {output_path}\"\n",
        "     else:\n",
        "         return \"Error: Molecule generation failed. Check logs for details.\"\n",
        "\n",
        "\n",
        " @function_tool(agent=workflow_agent)\n",
        " async def run_molecular_docking(ligand_sdf_name: str, protein_pdb: str, dock_mode: str = \"adgpu\"):\n",
        "     \"\"\"\n",
        "     Performs molecular docking of a ligand (SDF file) to a protein (PDB file).\n",
        "\n",
        "     Args:\n",
        "         ligand_sdf_name (str): Name of the input ligand SDF file located in the working directory (e.g., 'generated_mols.sdf').\n",
        "         protein_pdb (str): Path to the input protein PDB file (e.g., '/path/to/protein.pdb' or relative 'protein.pdb').\n",
        "         dock_mode (str): Docking engine to use, either 'adgpu' or 'vina'. Defaults to 'adgpu'.\n",
        "     \"\"\"\n",
        "     logging.info(f\"Tool 'run_molecular_docking' called with: ligand_sdf_name={ligand_sdf_name}, protein_pdb={protein_pdb}, dock_mode={dock_mode}\")\n",
        "\n",
        "     # Resolve protein PDB file path\n",
        "     protein_path = Path(protein_pdb)\n",
        "     if not protein_path.is_absolute():\n",
        "         protein_path = (WORKING_DIR / protein_pdb).resolve()\n",
        "     else:\n",
        "         protein_path = protein_path.resolve()\n",
        "\n",
        "     # Check inputs\n",
        "     ligand_path = WORKING_DIR / ligand_sdf_name\n",
        "     if not ligand_path.exists():\n",
        "         return f\"Error: Ligand SDF file not found at {ligand_path}\"\n",
        "     if not protein_path.exists():\n",
        "         return f\"Error: Protein PDB file not found at {protein_path}\"\n",
        "     if dock_mode not in [\"adgpu\", \"vina\"]:\n",
        "         return f\"Error: Invalid dock_mode '{dock_mode}'. Use 'adgpu' or 'vina'.\"\n",
        "\n",
        "     # Clear previous checkpoint\n",
        "     docker.clear_checkpoint()\n",
        "\n",
        "     # Run the step\n",
        "     success = await asyncio.to_thread(\n",
        "         docker.run,\n",
        "         ligand_sdf=ligand_sdf_name, # Pass name relative to working dir\n",
        "         protein_pdb=str(protein_path),\n",
        "         dock_mode=dock_mode\n",
        "     )\n",
        "\n",
        "     if success:\n",
        "         output_dir = WORKING_DIR / \"dock\" / dock_mode\n",
        "         return f\"Molecular docking ({dock_mode}) completed successfully. Results are in {output_dir}\"\n",
        "     else:\n",
        "         return f\"Error: Molecular docking ({dock_mode}) failed. Check logs for details.\"\n",
        "\n",
        "\n",
        " @function_tool(agent=workflow_agent)\n",
        " async def run_conformation_evaluation(mode: str, dock_output_dir_name: Optional[str] = None, mol_file_path: Optional[str] = None):\n",
        "     \"\"\"\n",
        "     Evaluates molecule conformations using the PB method.\n",
        "\n",
        "     Args:\n",
        "         mode (str): Evaluation mode: 'redock' (evaluates docking results) or 'mol' (evaluates a specific molecule file).\n",
        "         dock_output_dir_name (Optional[str]): Name of the docking output directory inside '<working_dir>/dock/' (e.g., 'adgpu' or 'vina'), required if mode is 'redock'.\n",
        "         mol_file_path (Optional[str]): Path to the input molecule file (e.g., 'ligands/mol1.sdf' or '/abs/path/mol1.pdbqt'), required if mode is 'mol'.\n",
        "     \"\"\"\n",
        "     logging.info(f\"Tool 'run_conformation_evaluation' called with: mode={mode}, dock_output_dir_name={dock_output_dir_name}, mol_file_path={mol_file_path}\")\n",
        "\n",
        "     # Parameter validation\n",
        "     if mode not in [\"redock\", \"mol\"]:\n",
        "         return f\"Error: Invalid evaluation mode '{mode}'. Use 'redock' or 'mol'.\"\n",
        "     if mode == \"redock\" and not dock_output_dir_name:\n",
        "         return \"Error: 'dock_output_dir_name' (e.g., 'adgpu' or 'vina') is required for 'redock' mode.\"\n",
        "     if mode == \"mol\" and not mol_file_path:\n",
        "         return \"Error: 'mol_file_path' is required for 'mol' mode.\"\n",
        "\n",
        "     # Prepare arguments for the evaluator\n",
        "     eval_args = {\"mode\": mode}\n",
        "     if mode == \"redock\":\n",
        "         # Construct full path to docking output directory\n",
        "         full_dock_output_dir = WORKING_DIR / \"dock\" / dock_output_dir_name\n",
        "         if not full_dock_output_dir.is_dir():\n",
        "              return f\"Error: Docking output directory '{full_dock_output_dir}' not found.\"\n",
        "         eval_args[\"dock_output_dir\"] = str(full_dock_output_dir)\n",
        "     elif mode == \"mol\":\n",
        "         # Resolve molecule file path\n",
        "         mol_path = Path(mol_file_path)\n",
        "         if not mol_path.is_absolute():\n",
        "             mol_path = (WORKING_DIR / mol_file_path).resolve()\n",
        "         else:\n",
        "             mol_path = mol_path.resolve()\n",
        "\n",
        "         if not mol_path.exists():\n",
        "             return f\"Error: Input molecule file not found at {mol_path}\"\n",
        "         eval_args[\"mol_file\"] = str(mol_path)\n",
        "\n",
        "     # Clear previous checkpoint\n",
        "     evaluator.clear_checkpoint()\n",
        "\n",
        "     # Run the step\n",
        "     success = await asyncio.to_thread(\n",
        "         evaluator.run,\n",
        "         **eval_args\n",
        "     )\n",
        "\n",
        "     if success:\n",
        "         output_dir = WORKING_DIR / \"eval\" / mode\n",
        "         return f\"Conformation evaluation ({mode}) completed successfully. Results are in {output_dir}\"\n",
        "     else:\n",
        "         return f\"Error: Conformation evaluation ({mode}) failed. Check logs for details.\"\n",
        "\n",
        "\n",
        " # --- Main Execution Logic ---\n",
        "\n",
        " async def run_workflow_with_agent():\n",
        "     \"\"\"Main async function to interact with the agent.\"\"\"\n",
        "     logging.info(\"Starting Workflow Manager with MCP Agent.\")\n",
        "     print(\"\\n--- Virtual Screening Workflow Assistant ---\")\n",
        "     print(f\"Working Directory: {WORKING_DIR}\")\n",
        "     print(\"Enter your request (e.g., 'Generate 3 molecules for protein.pdb ref A:123, then dock them with vina') or type 'exit'.\")\n",
        "\n",
        "     # Ensure working directory exists\n",
        "     WORKING_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "     # Clear all checkpoints at the start of a new session? Optional.\n",
        "     # print(\"Clearing previous checkpoints...\")\n",
        "     # for step_instance in [mol_generator, docker, evaluator]:\n",
        "     #     step_instance.clear_checkpoint()\n",
        "\n",
        "     while True:\n",
        "         try:\n",
        "             user_request = await asyncio.get_event_loop().run_in_executor(\n",
        "                 None, input, \"\\nUser > \"\n",
        "             )\n",
        "             user_request = user_request.strip()\n",
        "\n",
        "             if user_request.lower() == \"exit\":\n",
        "                 print(\"Exiting workflow manager.\")\n",
        "                 break\n",
        "\n",
        "             if not user_request:\n",
        "                 continue\n",
        "\n",
        "             print(\"\\nAssistant thinking...\")\n",
        "             logging.info(f\"Received user request: {user_request}\")\n",
        "\n",
        "             # Run the agent with the user request\n",
        "             result = await Runner.run(workflow_agent, user_request)\n",
        "\n",
        "             # Process and display the final output\n",
        "             final_output = []\n",
        "             if result and result.history:\n",
        "                  last_item = result.history[-1]\n",
        "                  # Check if the last item is a message from the assistant\n",
        "                  if isinstance(last_item, MessageOutputItem) and last_item.sender_name == workflow_agent.name:\n",
        "                      final_output.append(ItemHelpers.get_text_content(last_item))\n",
        "                  # Or if it's the output from the last tool call\n",
        "                  elif isinstance(last_item, ToolCallOutputItem):\n",
        "                      # Assuming tool output is simple text content\n",
        "                      final_output.append(str(last_item.content))\n",
        "                  else:\n",
        "                       # Fallback: try to get text from the last item, whatever it is\n",
        "                       try:\n",
        "                           final_output.append(ItemHelpers.get_text_content(last_item))\n",
        "                       except Exception:\n",
        "                            final_output.append(f\"Workflow finished. Last event: {type(last_item).__name__}\")\n",
        "\n",
        "                  # You might want to iterate through more of the history\n",
        "                  # to show intermediate steps or tool calls/results.\n",
        "                  # for item in result.history:\n",
        "                  #    # ... logic to display different item types ...\n",
        "\n",
        "             elif result and result.final_output:\n",
        "                 # Sometimes final_output might be populated directly\n",
        "                 final_output.append(str(result.final_output))\n",
        "             else:\n",
        "                 final_output.append(\"Assistant did not produce a final response.\")\n",
        "\n",
        "             print(\"\\nAssistant:\")\n",
        "             print(\"\\n\".join(final_output))\n",
        "             logging.info(f\"Agent final response: {' '.join(final_output)}\")\n",
        "\n",
        "\n",
        "         except KeyboardInterrupt:\n",
        "             print(\"\\nExiting workflow manager.\")\n",
        "             break\n",
        "         except Exception as e:\n",
        "             logging.error(f\"An error occurred in the main loop: {e}\", exc_info=True)\n",
        "             print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        " if __name__ == \"__main__\":\n",
        "     # Ensure API key is set\n",
        "     if API_KEY == \"YOUR_DEEPSEEK_API_KEY\" or not API_KEY:\n",
        "         print(\"Error: API_KEY environment variable not set.\")\n",
        "         print(\"Please set the API_KEY environment variable (e.g., in a .env file).\")\n",
        "         exit(1)\n",
        "\n",
        "     # Run the async main function\n",
        "     try:\n",
        "         asyncio.run(run_workflow_with_agent())\n",
        "     except Exception as e:\n",
        "         logging.critical(f\"Workflow execution failed critically: {e}\", exc_info=True)\n",
        "         print(f\"Critical error: {e}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "8TKIDPh6PugH"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}